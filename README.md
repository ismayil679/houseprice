# House Price Prediction Project

An optimized machine learning project to predict house prices using heavily tuned CatBoost with advanced feature engineering.

## ğŸ† Model Performance

**Optimized CatBoost**: **79,808 AZN RMSE** (Validation)
- Improved from baseline 81,771 â†’ 79,808 (2,000 AZN reduction!)
- RÂ² Score: 0.8030
- 5-Fold CV: 93,230 Â± 15,167 AZN

## ğŸ“ Project Structure

```
House_Pricing_Project/
â”œâ”€â”€ data/                              # Data files
â”‚   â”œâ”€â”€ binaaz_train.csv              # Training data with prices
â”‚   â”œâ”€â”€ binaaz_test.csv               # Test data (for predictions)
â”‚   â”œâ”€â”€ binaaz_sample.csv             # Sample data
â”‚   â””â”€â”€ baku_coordinates.xlsx         # Baku landmarks (130 locations)
â”‚
â”œâ”€â”€ src/                               # Source code
â”‚   â”œâ”€â”€ advanced_preprocessing.py     # Advanced feature engineering
â”‚   â”œâ”€â”€ optimized_train.py            # Hyperparameter tuning pipeline
â”‚   â”œâ”€â”€ optimized_evaluate.py         # Generate predictions
â”‚   â”œâ”€â”€ preprocessing.py              # Basic preprocessing (legacy)
â”‚   â”œâ”€â”€ train.py                      # Basic training (legacy)
â”‚   â””â”€â”€ evaluate.py                   # Basic evaluation (legacy)
â”‚
â”œâ”€â”€ models/                            # Saved models
â”‚   â”œâ”€â”€ advanced_preprocessor.pkl     # Advanced feature preprocessor
â”‚   â”œâ”€â”€ catboost_optimized_final.cbm  # Final model (full training data)
â”‚   â”œâ”€â”€ catboost_optimized_best.cbm   # Best validation model
â”‚   â””â”€â”€ optimization_results.json     # Optimization metadata
â”‚
â”œâ”€â”€ outputs/                           # Output files
â”‚   â””â”€â”€ predictions/                  # Prediction files
â”‚       â”œâ”€â”€ submission_latest.csv     # Latest predictions
â”‚       â””â”€â”€ submission_*.csv          # Timestamped predictions
â”‚
â”œâ”€â”€ requirements.txt                   # Python dependencies
â””â”€â”€ README.md                          # This file
```

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Train Optimized CatBoost Model

```bash
python src/optimized_train.py
```

This will:
- Load data with line terminator fixes
- Extract 20 advanced features (including distance to landmarks)
- Train 4 different CatBoost configurations
- Perform 5-fold cross-validation
- Select best model based on validation RMSE
- Train final model on full dataset

**Training time**: ~10 minutes

### 3. Generate Predictions

```bash
python src/optimized_evaluate.py
```

This will:
- Load the optimized CatBoost model
- Generate predictions on test set
- Save to `outputs/predictions/submission_latest.csv`

## ğŸ“Š Features

The optimized model uses **20 advanced features**:

**Core Features (8):**
- `area`: Property area in mÂ²
- `room_count`: Number of rooms
- `floor`: Floor number
- `total_floors`: Total floors in building
- `lat`, `lon`: Geographic coordinates
- `dist_from_center`: Distance from Baku city center (40.4093, 49.8671)
- `city_baki`: Located in Baku

**Binary Features (5):**
- `has_deed`: Property has deed (KupÃ§a)
- `has_mortgage`: Mortgage available (Ä°poteka)
- `is_owner`: Posted by owner
- `is_agent`: Posted by agent
- `is_new_building`: New construction

**Engineered Features (4):**
- `floor_ratio`: floor / (total_floors + 1)
- `area_per_room`: area / (room_count + 1)
- `title_length`: Length of listing title
- `desc_length`: Length of description

**Distance Features (3):** ğŸ†•
- `dist_to_nearest_landmark`: Distance to nearest important location
- `dist_to_nearest_5_landmarks`: Avg distance to 5 nearest landmarks
- `dist_to_nearest_10_landmarks`: Avg distance to 10 nearest landmarks

*Based on 130 important locations in Baku (metro stations, monuments, parks, etc.)*

## ğŸ“ˆ Model Performance

### Optimization Results

| Configuration | Validation RMSE | MAE | RÂ² |
|--------------|----------------|------|-----|
| Baseline | 80,374 AZN | 30,048 | 0.8002 |
| **Optimized V1** â­ | **79,808 AZN** | **29,296** | **0.8030** |
| Optimized V2 | 80,216 AZN | 29,823 | 0.8010 |
| Optimized V3 | 80,997 AZN | 29,297 | 0.7971 |

### Feature Importance (Top 10)

1. **area** (26.9%) - Property size
2. **lat** (8.9%) - Latitude
3. **area_per_room** (8.8%) - Size efficiency
4. **room_count** (8.0%) - Number of rooms
5. **dist_to_nearest_10_landmarks** (6.6%) ğŸ†•
6. **dist_from_center** (6.3%) - Distance from center
7. **dist_to_nearest_5_landmarks** (6.0%) ğŸ†•
8. **total_floors** (5.6%) - Building height
9. **floor_ratio** (5.3%) - Relative floor position
10. **lon** (5.2%) - Longitude

Distance features contribute **15.9%** to predictions!

## ğŸ”§ Optimization Details

### CatBoost Configuration (Best: Optimized V1)

```python
{
    'iterations': 3000,
    'learning_rate': 0.02,        # Lower LR for stability
    'depth': 10,                  # Deeper trees
    'l2_leaf_reg': 5,             # Regularization
    'subsample': 0.75,
    'colsample_bylevel': 0.8,
    'min_data_in_leaf': 15,
    'bagging_temperature': 0.5,
    'border_count': 254,
    'early_stopping_rounds': 150
}
```

### Training Strategy

1. **Stage 1**: Baseline model (2000 iterations)
2. **Stage 2**: Optimized V1 - Deeper trees + lower LR
3. **Stage 3**: Optimized V2 - Regularization focus
4. **Stage 4**: Optimized V3 - Aggressive boosting
5. **Stage 5**: Best model on full training data
6. **Validation**: 5-fold cross-validation

### Feature Engineering Pipeline

1. Parse numeric values from text (area: "115 mÂ²" â†’ 115.0)
2. Extract floor information ("5 / 9" â†’ floor=5, total=9)
3. Calculate distances to 130 Baku landmarks
4. Create ratio features (floor_ratio, area_per_room)
5. Binary encoding (has_deed, is_owner, etc.)
6. Handle missing values with median imputation
7. StandardScaler normalization

## ğŸ“ Key Improvements

### From Baseline to Optimized

âœ… **Added distance features** (+3 features from baku_coordinates.xlsx)  
âœ… **Engineered ratio features** (floor_ratio, area_per_room)  
âœ… **Fixed line terminator issues** in CSV files  
âœ… **Hyperparameter tuning** (tested 4 configurations)  
âœ… **Cross-validation** (5-fold for robustness)  
âœ… **Deeper trees** (depth 10 vs 8)  
âœ… **Lower learning rate** (0.02 vs 0.05)  
âœ… **More iterations** (3000 vs 1000)  

**Result**: 81,771 â†’ **79,808 RMSE** (-2,000 AZN improvement!)

## ğŸ¯ Competition Metric

Primary metric: **RMSE** (Root Mean Squared Error)

## ğŸ“¤ Submission

Submit: `outputs/predictions/submission_latest.csv`

Format:
```csv
_id,price
20886,181234.56
117465,95678.90
...
```

Expected performance: **~80,000 AZN RMSE**
